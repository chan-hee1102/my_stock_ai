# -*- coding: utf-8 -*-
import pandas as pd
import pandas_ta as ta
import yfinance as yf
from lightgbm import LGBMClassifier
import joblib
from datetime import datetime, timedelta
import os
import warnings
import logging 
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# ì›Œë‹ ë° ë¡œê·¸ ì œì–´ (ê¹¨ë—í•œ í„°ë¯¸ë„ ì¶œë ¥ ìœ ì§€)
warnings.filterwarnings("ignore")
logging.getLogger("lightgbm").setLevel(logging.ERROR) 

# =========================
# 1. ì„¤ì • ë° ê²½ë¡œ
# =========================
OUTPUT_DIR = "outputs"
MODEL_NAME = "stock_model.pkl"
LOG_NAME = "model_history.csv" 
TRAIN_YEARS = 5

def get_latest_selected_stocks():
    """outputs í´ë”ì—ì„œ ê°€ì¥ ìµœê·¼ì— ì„ ì •ëœ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        if not os.path.exists(OUTPUT_DIR):
            os.makedirs(OUTPUT_DIR)
            return None
            
        files = [f for f in os.listdir(OUTPUT_DIR) if f.startswith("final_result_") and f.endswith(".csv")]
        if not files:
            return None
        
        latest_file = sorted(files)[-1]
        print(f"ğŸ“‚ [ì‹œìŠ¤í…œ] ìµœì‹  ì„ ì • íŒŒì¼ ë¶„ì„ ì¤‘: {latest_file}")
        df = pd.read_csv(os.path.join(OUTPUT_DIR, latest_file))
        return [str(code).zfill(6) for code in df['ì¢…ëª©ì½”ë“œ'].tolist()]
    except Exception as e:
        print(f"âŒ [ì—ëŸ¬] íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return None

def extract_ml_features(df, market_df, nasdaq_df, vix_df, dxy_df, tnx_df, gold_df):
    """
    [ìµœì¢… ì§„í™”] êµ­ì±„ ê¸ˆë¦¬, ê¸ˆ ì„ ë¬¼, ìš”ì¼ ë°ì´í„°ê¹Œì§€ í¬í•¨í•œ ì´ˆê³ ë„í™” í”¼ì²˜ ë¡œì§
    """
    try:
        if len(df) < 60: return None 
        
        # 1. ê°œë³„ ì¢…ëª© ê¸°ìˆ ì  ì§€í‘œ (RSI, ë³¼ë¦°ì €ë°´ë“œ, ì´í‰ì„ )
        df['rsi'] = ta.rsi(df['Close'], length=14)
        bb = ta.bbands(df['Close'], length=20, std=2)
        l_col = [c for c in bb.columns if 'BBL' in c][0]
        u_col = [c for c in bb.columns if 'BBU' in c][0]
        df['bb_per'] = (df['Close'] - bb[l_col]) / (bb[u_col] - bb[l_col])
        
        ma5, ma20 = ta.sma(df['Close'], 5), ta.sma(df['Close'], 20)
        df['ma_diff'] = (ma5 - ma20) / ma20
        
        # 2. ìˆ˜ê¸‰ ë° ê±°ë˜ëŸ‰ íŒ¨í„´
        vol_up = (df['Volume'] > df['Volume'].shift(1)).astype(int)
        df['vol_consecutive_days'] = vol_up.groupby((vol_up != vol_up.shift()).cumsum()).cumsum()
        df['vol_spike_ratio'] = df['Volume'] / ta.sma(df['Volume'], 20)
        
        # 3. ìº”ë“¤ ë¶„ì„ ë° ì‹œì¥ ëŒ€ë¹„ ìƒëŒ€ ê°•ë„
        df['candle_body'] = (df['Close'] - df['Open']) / (df['High'] - df['Low'] + 1e-9)
        df = df.join(market_df.rename("market_close"), how='left')
        df['relative_strength'] = df['Close'].pct_change(5) - df['market_close'].pct_change(5)
        
        # 4. ëª¨ë©˜í…€ ë° ë³€ë™ì„±
        macd = ta.macd(df['Close'])
        df['macd_hist'] = macd['MACDh_12_26_9']
        df['mfi'] = ta.mfi(df['High'], df['Low'], df['Close'], df['Volume'], length=14)
        df['atr_ratio'] = ta.atr(df['High'], df['Low'], df['Close'], length=14) / df['Close']

        # 5. ìŠ¤í† ì¼€ìŠ¤í‹± ë° ì´ê²©ë„
        stoch = ta.stoch(df['High'], df['Low'], df['Close'], k=14, d=3, smooth_k=3)
        df['stoch_k'] = stoch['STOCHk_14_3_3']
        ma60 = ta.sma(df['Close'], 60)
        df['disparity_60'] = (df['Close'] / ma60) * 100
        
        # 6. ê°€ê²© ë³€ë™í­ ë° ê±°ë˜ëŒ€ê¸ˆ ê°€ì†ë„
        df['price_range'] = (df['High'] - df['Low']) / df['Close']
        df['vol_roc'] = ta.roc(df['Volume'], length=5)

        # 7. [ì¶”ê°€] ìš”ì¼ í”¼ì²˜ (ì›”=0, ê¸ˆ=4) - ìš”ì¼ë³„ ì‹¬ë¦¬ íŒ¨í„´ ë°˜ì˜
        df['day_of_week'] = df.index.dayofweek

        # 8. [ë§¤í¬ë¡œ í”¼ì²˜] ë‚˜ìŠ¤ë‹¥, VIX, ë‹¬ëŸ¬, êµ­ì±„ê¸ˆë¦¬, ê¸ˆ ì„ ë¬¼ ìˆ˜ìµë¥ 
        df = df.join(nasdaq_df.rename("nasdaq_return"), how='left')
        df = df.join(vix_df.rename("vix_close"), how='left')
        df = df.join(dxy_df.rename("dxy_return"), how='left')
        df = df.join(tnx_df.rename("tnx_close"), how='left')
        df = df.join(gold_df.rename("gold_return"), how='left')
        
        return df.dropna()
    except Exception:
        return None

def save_training_log(accuracy, feature_list):
    """í•™ìŠµ ê²°ê³¼ë¥¼ CSV íŒŒì¼ì— ëˆ„ì  ê¸°ë¡í•˜ì—¬ ì„±ëŠ¥ì„ ì¶”ì í•©ë‹ˆë‹¤."""
    log_data = {
        'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'accuracy': round(accuracy * 100, 2),
        'feature_count': len(feature_list),
        'features': ", ".join(feature_list)
    }
    df_log = pd.DataFrame([log_data])
    if not os.path.exists(LOG_NAME):
        df_log.to_csv(LOG_NAME, index=False, encoding='utf-8-sig')
    else:
        df_log.to_csv(LOG_NAME, mode='a', header=False, index=False, encoding='utf-8-sig')
    print(f"ğŸ“ [ê¸°ë¡] í•™ìŠµ ê²°ê³¼ê°€ {LOG_NAME}ì— ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")

def train_specialized_model():
    """ì´ˆê³ ë„í™” íŒ¨í„´ ë¶„ì„ ë° ëª¨ë¸ í•™ìŠµ ì‹¤í–‰ ë£¨í‹´"""
    study_list = get_latest_selected_stocks()
    if not study_list:
        print("âš ï¸ [ì•Œë¦¼] ì„ ì •ëœ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸš€ [ì§„í–‰] {len(study_list)}ê°œ ì¢…ëª© + ê¸€ë¡œë²Œ ê±°ì‹œì§€í‘œ í’€íŒ¨í‚¤ì§€ í•™ìŠµ ì‹œì‘")
    
    end_date = datetime.now()
    start_date = end_date - timedelta(days=365 * TRAIN_YEARS)
    
    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ì¢…í•©)
    kospi_data = yf.download("^KS11", start=start_date, end=end_date, progress=False)['Close']
    kosdaq_data = yf.download("^KQ11", start=start_date, end=end_date, progress=False)['Close']
    nasdaq_data = yf.download("^IXIC", start=start_date, end=end_date, progress=False)['Close']
    vix_data = yf.download("^VIX", start=start_date, end=end_date, progress=False)['Close']
    dxy_data = yf.download("DX-Y.NYB", start=start_date, end=end_date, progress=False)['Close']
    tnx_data = yf.download("^TNX", start=start_date, end=end_date, progress=False)['Close'] # 10ë…„ë¬¼ ê¸ˆë¦¬
    gold_data = yf.download("GC=F", start=start_date, end=end_date, progress=False)['Close'] # ê¸ˆ ì„ ë¬¼
    
    nasdaq_return = nasdaq_data.pct_change()
    dxy_return = dxy_data.pct_change()
    gold_return = gold_data.pct_change()
    
    # ë°ì´í„° ì •ë¦¬ í•¨ìˆ˜
    def clean_ser(ser):
        return ser.iloc[:, 0] if isinstance(ser, pd.DataFrame) else ser

    kospi_data = clean_ser(kospi_data)
    kosdaq_data = clean_ser(kosdaq_data)
    nasdaq_return = clean_ser(nasdaq_return)
    vix_data = clean_ser(vix_data)
    dxy_return = clean_ser(dxy_return)
    tnx_data = clean_ser(tnx_data)
    gold_return = clean_ser(gold_return)
    
    all_data = []
    feature_columns = [
        'rsi', 'bb_per', 'ma_diff', 'vol_consecutive_days', 'vol_spike_ratio', 
        'candle_body', 'relative_strength', 'macd_hist', 'mfi', 'atr_ratio',
        'stoch_k', 'disparity_60', 'price_range', 'vol_roc', 'day_of_week',
        'nasdaq_return', 'vix_close', 'dxy_return', 'tnx_close', 'gold_return'
    ]
    
    for code in study_list:
        is_kospi = code.startswith(('0', '1', '2'))
        ticker = f"{code}.KS" if is_kospi else f"{code}.KQ"
        target_market = kospi_data if is_kospi else kosdaq_data
        
        try:
            df = yf.download(ticker, start=start_date, end=end_date, progress=False)
            if df.empty: continue
            if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
            
            processed_df = extract_ml_features(df, target_market, nasdaq_return, vix_data, dxy_return, tnx_data, gold_return)
            if processed_df is not None:
                # íƒ€ê²Ÿ: ë‚´ì¼ ì¢…ê°€ê°€ ì˜¤ëŠ˜ë³´ë‹¤ ìƒìŠ¹í•˜ë©´ 1
                processed_df['target'] = (processed_df['Close'].shift(-1) > processed_df['Close']).astype(int)
                all_data.append(processed_df[feature_columns + ['target']].dropna())
        except Exception:
            continue

    if not all_data:
        print("âŒ [ì—ëŸ¬] í•™ìŠµ ë°ì´í„° ë¶€ì¡±")
        return

    train_set = pd.concat(all_data)
    X, y = train_set[feature_columns], train_set['target']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    print(f"ğŸ“Š [ë¶„ì„] ì´ {len(train_set)}ê°œì˜ ë§¤ë§¤ íŒ¨í„´ í•™ìŠµ ì¤‘ (ê¸€ë¡œë²Œ ë§¤í¬ë¡œ ë³€ìˆ˜ í†µí•©)...")
    
    # ìµœì¢… ìµœì í™” í•˜ì´í¼íŒŒë¼ë¯¸í„°
    model = LGBMClassifier(
        n_estimators=700, 
        learning_rate=0.007, 
        max_depth=9,
        num_leaves=63, 
        min_child_samples=30, 
        random_state=42, 
        verbosity=-1
    )
    
    model.fit(X_train, y_train)
    acc = accuracy_score(y_test, model.predict(X_test))
    print(f"\nğŸ¯ [ê²°ê³¼] AI ìµœì¢… ì´ˆê³ ë„í™” ì •í™•ë„: {round(acc * 100, 2)}%")
    
    # ì¤‘ìš”ë„ ë¶„ì„
    importances = pd.DataFrame({
        'Feature': feature_columns,
        'Importance': model.feature_importances_
    }).sort_values(by='Importance', ascending=False)
    
    print("\nğŸ” [ë¶„ì„] ì–´ë–¤ ì§€í‘œê°€ ê°€ì¥ ì¤‘ìš”í–ˆë‚˜ìš”? (Top 10)")
    print(importances.head(10).to_string(index=False))
    print("-" * 50)
    
    save_training_log(acc, feature_columns)
    model.fit(X, y)
    joblib.dump(model, MODEL_NAME)
    print(f"âœ… [ì™„ë£Œ] ì „ ì„¸ê³„ ë§¤í¬ë¡œê°€ í†µí•©ëœ ìµœê°• ëª¨ë¸ ì €ì¥ ì™„ë£Œ")

if __name__ == "__main__":
    train_specialized_model()