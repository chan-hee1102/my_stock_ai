# -*- coding: utf-8 -*-
import pandas as pd
import pandas_ta as ta
import yfinance as yf
from lightgbm import LGBMClassifier
import joblib
from datetime import datetime, timedelta
import os
import warnings
import logging 
import streamlit as st
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# 1. ì‹œìŠ¤í…œ ì„¤ì • ë° í™˜ê²½ ë³€ìˆ˜ ì²˜ë¦¬
warnings.filterwarnings("ignore")
logging.getLogger("lightgbm").setLevel(logging.ERROR) 

# [í•µì‹¬ ë³´ì •] ê¹ƒí—ˆë¸Œ ì•¡ì…˜ê³¼ ìŠ¤íŠ¸ë¦¼ë¦¿ í™˜ê²½ ëª¨ë‘ì—ì„œ API í‚¤ë¥¼ ì¶©ëŒ ì—†ì´ ê°€ì ¸ì˜¤ëŠ” ìµœì í™” ë¡œì§
def get_api_key():
    """
    st.secrets ì°¸ì¡° ì‹œ ë°œìƒí•˜ëŠ” AttributeError ë° KeyErrorë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ 
    hasattr ê²€ì‚¬ì™€ í™˜ê²½ ë³€ìˆ˜(os.environ) ìš°ì„  ì°¸ì¡° ë°©ì‹ì„ ê²°í•©í–ˆìŠµë‹ˆë‹¤.
    """
    # 1ìˆœìœ„: ê¹ƒí—ˆë¸Œ ì•¡ì…˜ í™˜ê²½ë³€ìˆ˜ í™•ì¸
    api_key = os.environ.get("GROQ_API_KEY")
    
    # 2ìˆœìœ„: ê¹ƒí—ˆë¸Œ ì•¡ì…˜ì— ì—†ì„ ê²½ìš° ìŠ¤íŠ¸ë¦¼ë¦¿ Secrets í™•ì¸ (ë³´ì•ˆ ê²€ì‚¬ í¬í•¨)
    if not api_key:
        if hasattr(st, "secrets"):
            try:
                api_key = st.secrets.get("GROQ_API_KEY")
            except Exception:
                api_key = None
    
    return api_key.strip() if api_key else ""

# ê²½ë¡œ ë° ìƒìˆ˜ ì„¤ì •
OUTPUT_DIR = "outputs"
MODEL_NAME = "stock_model.pkl"
LOG_NAME = "model_history.csv" 
TRAIN_YEARS = 5

def get_latest_selected_stocks():
    """outputs í´ë”ì—ì„œ ê°€ì¥ ìµœê·¼ì— ì„ ì •ëœ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        if not os.path.exists(OUTPUT_DIR):
            os.makedirs(OUTPUT_DIR)
            return None
            
        files = [f for f in os.listdir(OUTPUT_DIR) if f.startswith("final_result_") and f.endswith(".csv")]
        if not files:
            return None
        
        latest_file = sorted(files)[-1]
        print(f"ğŸ“‚ [ì‹œìŠ¤í…œ] ìµœì‹  ì„ ì • íŒŒì¼ ë¶„ì„ ì¤‘: {latest_file}")
        df = pd.read_csv(os.path.join(OUTPUT_DIR, latest_file))
        return [str(code).zfill(6) for code in df['ì¢…ëª©ì½”ë“œ'].tolist()]
    except Exception as e:
        print(f"âŒ [ì—ëŸ¬] íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return None

def extract_ml_features(df, market_df, nasdaq_df, vix_df, dxy_df, tnx_df, gold_df):
    """
    [í•´ê²°] ì‹œê°„ëŒ€(Timezone) ì¶©ëŒì„ ë°©ì§€í•˜ë©° 22ê°œì˜ í”¼ì²˜ë¥¼ ì¶”ì¶œí•˜ëŠ” ì—”ì§„
    """
    try:
        if len(df) < 60: return None 
        
        # ëª¨ë“  ë°ì´í„°ì˜ ì‹œê°„ëŒ€ ì •ë³´ë¥¼ ì œê±°í•˜ì—¬ ë³‘í•© ì—ëŸ¬ ë°©ì§€
        df.index = df.index.tz_localize(None)
        
        # 1. ê°œë³„ ì¢…ëª© ê¸°ìˆ ì  ì§€í‘œ
        df['rsi'] = ta.rsi(df['Close'], length=14)
        bb = ta.bbands(df['Close'], length=20, std=2)
        l_col = [c for c in bb.columns if 'BBL' in c][0]
        u_col = [c for c in bb.columns if 'BBU' in c][0]
        df['bb_per'] = (df['Close'] - bb[l_col]) / (bb[u_col] - bb[l_col])
        
        ma5, ma20 = ta.sma(df['Close'], 5), ta.sma(df['Close'], 20)
        df['ma_diff'] = (ma5 - ma20) / (ma20 + 1e-9)
        
        # 2. ê±°ë˜ëŸ‰ ë° ìº”ë“¤ ë¶„ì„
        vol_up = (df['Volume'] > df['Volume'].shift(1)).astype(int)
        df['vol_consecutive_days'] = vol_up.groupby((vol_up != vol_up.shift()).cumsum()).cumsum()
        df['vol_spike_ratio'] = df['Volume'] / (ta.sma(df['Volume'], 20) + 1e-9)
        df['candle_body'] = (df['Close'] - df['Open']) / (df['High'] - df['Low'] + 1e-9)
        
        # 3. ì‹œì¥ ëŒ€ë¹„ ìƒëŒ€ ê°•ë„ (RS)
        m_series = market_df.squeeze()
        if isinstance(m_series, pd.DataFrame): m_series = m_series.iloc[:, 0]
        m_series.index = m_series.index.tz_localize(None)
        m_series.name = "market_close"
        
        df = df.join(m_series, how='left').ffill()
        df['relative_strength'] = df['Close'].pct_change(5) - df['market_close'].pct_change(5)
        
        # 4. ëª¨ë©˜í…€ ë° ë³´ì¡° ì§€í‘œ
        macd = ta.macd(df['Close'])
        df['macd_hist'] = macd['MACDh_12_26_9']
        df['mfi'] = ta.mfi(df['High'], df['Low'], df['Close'], df['Volume'], length=14)
        df['atr_ratio'] = ta.atr(df['High'], df['Low'], df['Close'], length=14) / (df['Close'] + 1e-9)
        
        stoch = ta.stoch(df['High'], df['Low'], df['Close'])
        df['stoch_k'] = stoch['STOCHk_14_3_3']
        df['disparity_60'] = (df['Close'] / (ta.sma(df['Close'], 60) + 1e-9)) * 100
        df['price_range'] = (df['High'] - df['Low']) / (df['Close'] + 1e-9)
        df['vol_roc'] = ta.roc(df['Volume'], length=5)
        df['range_roc'] = ta.roc(df['price_range'], length=5)
        df['day_of_week'] = df.index.dayofweek
        
        # 5. ë§¤í¬ë¡œ ë°ì´í„° ë³‘í•©
        for ser, name in zip([nasdaq_df, vix_df, dxy_df, tnx_df, gold_df], 
                             ["nasdaq_return", "vix_close", "dxy_return", "tnx_close", "gold_return"]):
            s = ser.squeeze()
            if isinstance(s, pd.DataFrame): s = s.iloc[:, 0]
            s.index = s.index.tz_localize(None)
            s.name = name
            df = df.join(s, how='left').ffill()
            
        # ë‚˜ìŠ¤ë‹¥ ì„ ë¬¼ ëŒ€ìš©ê°’ ê³„ì‚°
        df['nasdaq_f_return'] = df['nasdaq_return'].shift(-1).fillna(0)
        
        return df.dropna()
    except Exception as e:
        print(f"âš ï¸ ì§€í‘œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def save_training_log(accuracy, feature_list):
    log_data = {
        'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'accuracy': round(accuracy * 100, 2),
        'feature_count': len(feature_list),
        'features': ", ".join(feature_list)
    }
    df_log = pd.DataFrame([log_data])
    if not os.path.exists(LOG_NAME):
        df_log.to_csv(LOG_NAME, index=False, encoding='utf-8-sig')
    else:
        df_log.to_csv(LOG_NAME, mode='a', header=False, index=False, encoding='utf-8-sig')

def train_specialized_model():
    study_list = get_latest_selected_stocks()
    api_key = get_api_key() # [ë³´ì • ì ìš©] ìµœì í™”ëœ í‚¤ ìˆ˜ì§‘ ë¡œì§ ì‚¬ìš©
    
    if not study_list:
        print("âš ï¸ [ì•Œë¦¼] ì„ ì •ëœ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸš€ [ì§„í–‰] {len(study_list)}ê°œ ì¢…ëª© ê¸°ë°˜ AI ëª¨ë¸ ì¬í•™ìŠµ ì‹œì‘ (v1.7)")
    
    end_date = datetime.now()
    start_date = end_date - timedelta(days=365 * TRAIN_YEARS)
    
    # ê¸€ë¡œë²Œ ë§¤í¬ë¡œ ë°ì´í„° ìˆ˜ì§‘
    tickers = ["^KS11", "^KQ11", "^IXIC", "^VIX", "DX-Y.NYB", "^TNX", "GC=F"]
    macro_raw = yf.download(tickers, start=start_date, end=end_date, progress=False)['Close'].ffill()
    
    kospi = macro_raw['^KS11']
    kosdaq = macro_raw['^KQ11']
    nasdaq_ret = macro_raw['^IXIC'].pct_change()
    vix = macro_raw['^VIX']
    dxy_ret = macro_raw['DX-Y.NYB'].pct_change()
    tnx = macro_raw['^TNX']
    gold_ret = macro_raw['GC=F'].pct_change()
    
    all_data = []
    feature_columns = [
        'rsi', 'bb_per', 'ma_diff', 'vol_consecutive_days', 'vol_spike_ratio', 
        'candle_body', 'relative_strength', 'macd_hist', 'mfi', 'atr_ratio',
        'stoch_k', 'disparity_60', 'price_range', 'vol_roc', 'range_roc',
        'day_of_week', 'nasdaq_return', 'vix_close', 'dxy_return', 'tnx_close', 
        'gold_return', 'nasdaq_f_return'
    ]
    
    for code in study_list:
        ticker = f"{code}.KS" if code.startswith(('0', '1', '2')) else f"{code}.KQ"
        market = kospi if ".KS" in ticker else kosdaq
        
        try:
            df = yf.download(ticker, start=start_date, end=end_date, progress=False)
            if df.empty or len(df) < 100: continue
            if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
            
            p_df = extract_ml_features(df, market, nasdaq_ret, vix, dxy_ret, tnx, gold_ret)
            if p_df is not None:
                p_df['target'] = (p_df['Close'].shift(-1) > p_df['Close']).astype(int)
                all_data.append(p_df[feature_columns + ['target']].dropna())
        except: continue

    if not all_data:
        print("âŒ [ì—ëŸ¬] ìœ íš¨ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨. API í‚¤ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ í™•ì¸.")
        return

    train_set = pd.concat(all_data)
    X, y = train_set[feature_columns], train_set['target']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    model = LGBMClassifier(
        n_estimators=1000, learning_rate=0.01, max_depth=10,
        num_leaves=127, min_child_samples=20, random_state=42, verbosity=-1
    )
    
    model.fit(X_train, y_train)
    acc = accuracy_score(y_test, model.predict(X_test))
    print(f"\nğŸ¯ [ê²°ê³¼] AI ëª¨ë¸ ì •í™•ë„: {round(acc * 100, 2)}% (í•™ìŠµë°ì´í„°: {len(train_set)}ê±´)")
    
    save_training_log(acc, feature_columns)
    model.fit(X, y)
    joblib.dump(model, MODEL_NAME)
    print(f"âœ… [ì™„ë£Œ] {MODEL_NAME} ê°±ì‹  ì™„ë£Œ.")

if __name__ == "__main__":
    train_specialized_model()