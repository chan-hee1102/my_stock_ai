# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import os
from groq import Groq
from datetime import datetime

# 1) í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI STOCK COMMANDER", layout="wide")

# 2) ë””ìì¸ CSS (ì„ì°¬í¬ë‹˜ì˜ ì‹œê·¸ë‹ˆì²˜ ë¸”ë™ & ë¯¼íŠ¸ ë””ìì¸)
st.markdown("""
    <style>
    .stApp { background-color: #05070a; }
    [data-testid="stHorizontalBlock"] > div {
        background-color: #1c2128; border-radius: 15px; padding: 25px; border: 1px solid #30363d;
    }
    .section-header { 
        color: #00e5ff !important; font-size: 1.5rem !important; font-weight: 800; 
        margin-bottom: 25px; border-left: 6px solid #00e5ff; padding-left: 15px; 
    }
    div[data-testid="stColumn"]:nth-of-type(1) .stButton > button {
        width: 100% !important; background-color: transparent !important; color: #ffffff !important;
        border: none !important; font-size: 2.2rem !important; font-weight: 800 !important;
        text-align: left !important; padding: 12px 0px !important; transition: 0.3s;
    }
    div[data-testid="stColumn"]:nth-of-type(1) .stButton > button:hover { color: #00e5ff !important; transform: translateX(8px); }
    .report-box { background-color: #0d1117; border: 1px solid #30363d; border-radius: 12px; padding: 25px; margin-bottom: 20px; }
    .report-text { color: #e0e6ed !important; font-size: 1.2rem !important; line-height: 1.8; }
    .highlight-mint { color: #00e5ff !important; font-weight: 800; }
    div[data-testid="stChatInput"] { background-color: #ffffff !important; border-radius: 15px !important; padding: 10px !important; }
    div[data-testid="stChatInput"] textarea { color: #000000 !important; font-size: 1.15rem !important; }
    </style>
    """, unsafe_allow_html=True)

# 3) ë°ì´í„° ë¡œë“œ ë¡œì§
def load_data():
    out_dir = "outputs"
    if not os.path.exists(out_dir): return None, None
    # 'final_result_'ë¡œ ì‹œì‘í•˜ëŠ” ê°€ì¥ ìµœì‹  CSV íŒŒì¼ íƒìƒ‰
    files = [f for f in os.listdir(out_dir) if f.startswith("final_result_") and f.endswith(".csv")]
    if not files: return None, None
    latest_file = sorted(files)[-1]
    
    try:
        raw_date = latest_file.split('_')[-1].replace('.csv', '')
        date_str = f"{raw_date[:4]}-{raw_date[4:6]}-{raw_date[6:]}"
    except:
        date_str = datetime.now().strftime('%Y-%m-%d')
        
    df = pd.read_csv(os.path.join(out_dir, latest_file))
    if "ì¢…ëª©ì½”ë“œ" in df.columns: 
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).str.zfill(6)
    return df, date_str

data, data_date = load_data()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state: 
    st.session_state.messages = []
if data is not None and "selected_stock" not in st.session_state:
    st.session_state.selected_stock = data.iloc[0].to_dict()

# Groq í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (secrets.tomlì—ì„œ ê´€ë¦¬)
def get_groq_client():
    key = st.secrets.get("GROQ_API_KEY")
    if not key: return None
    return Groq(api_key=key)

client = get_groq_client()

# 4) ë©”ì¸ ë ˆì´ì•„ì›ƒ êµ¬ì„±
if data is not None:
    col_list, col_chat = st.columns([2, 8])

    # ì™¼ìª½ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì„¹ì…˜
    with col_list:
        st.markdown(f'<div class="section-header">ğŸ“‚ {data_date} í¬ì°© ì¢…ëª©</div>', unsafe_allow_html=True)
        with st.container(height=850):
            for i, (idx, row) in enumerate(data.iterrows()):
                is_selected = st.session_state.selected_stock['ì¢…ëª©ëª…'] == row['ì¢…ëª©ëª…']
                display_name = f"â–¶ {row['ì¢…ëª©ëª…']} â—€" if is_selected else f"  {row['ì¢…ëª©ëª…']}"
                if st.button(display_name, key=f"stock_btn_{i}"):
                    st.session_state.selected_stock = row.to_dict()
                    st.session_state.messages = [] # ì¢…ëª© ë³€ê²½ ì‹œ ëŒ€í™” ë¦¬ì…‹
                    st.rerun()
                st.markdown("<hr style='margin:5px 0; border:0.5px solid #30363d; opacity:0.3;'>", unsafe_allow_html=True)

    # ì˜¤ë¥¸ìª½ ì±„íŒ… ë¦¬í¬íŠ¸ ì„¹ì…˜
    with col_chat:
        stock = st.session_state.selected_stock
        st.markdown(f'<div class="section-header">ğŸ’¬ {stock["ì¢…ëª©ëª…"]} AI ì •ë°€ ë¦¬í¬íŠ¸</div>', unsafe_allow_html=True)
        
        # ê³ ì • ìš”ì•½ ì •ë³´ ë°•ìŠ¤
        st.markdown(f"""
        <div class="report-box"><div class="report-text">
            <span class="highlight-mint">â— ë¶„ì„ ëŒ€ìƒ:</span> {stock["ì¢…ëª©ëª…"]} ({stock.get('ì¢…ëª©ì½”ë“œ', '000000')})<br>
            <span class="highlight-mint">â— AI ì—”ì§„:</span> Llama-3.3-70B (High-Speed Inference)<br>
            <span class="highlight-mint">â— ìƒíƒœ:</span> Groq ì´ˆê³ ì† ì—”ì§„ ë° ëŒ€í™” ê¸°ë¡ ë°˜ì˜ ì¤‘
        </div></div>
        """, unsafe_allow_html=True)

        # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ ì˜ì—­
        chat_container = st.container(height=650)
        with chat_container:
            for m in st.session_state.messages:
                with st.chat_message(m["role"]):
                    st.markdown(f"<div style='font-size:1.15rem; color:#ffffff;'>{m['content']}</div>", unsafe_allow_html=True)

        # ì‚¬ìš©ì ì…ë ¥ ë° ì‘ë‹µ ë¡œì§
        if prompt := st.chat_input(f"{stock['ì¢…ëª©ëª…']}ì— ëŒ€í•´ ììœ ë¡­ê²Œ ëŒ€í™”í•´ë³´ì„¸ìš”!"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with chat_container:
                with st.chat_message("user"):
                    st.markdown(f"<div style='font-size:1.15rem; color:#ffffff;'>{prompt}</div>", unsafe_allow_html=True)
            
            if client:
                with st.status("AI ë¶„ì„ê´€ì´ ë°ì´í„° ê²€í†  ì¤‘...", expanded=True) as status:
                    try:
                        # ëŒ€í™” ë§¥ë½ í¬í•¨ (ìµœê·¼ 10ê°œ ëŒ€í™”)
                        history = [{"role": "system", "content": f"ë‹¹ì‹ ì€ {stock['ì¢…ëª©ëª…']} ì „ë¬¸ ì£¼ì‹ ì „ëµê°€ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ë‚ ì§œëŠ” {datetime.now().strftime('%Y-%m-%d')}ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”."}]
                        for m in st.session_state.messages[-10:]:
                            history.append({"role": m["role"], "content": m["content"]})
                        
                        # API í˜¸ì¶œ (2026ë…„ ê¸°ì¤€ llama-3.3 ëª¨ë¸ ì‚¬ìš©)
                        completion = client.chat.completions.create(
                            model="llama-3.3-70b-versatile",
                            messages=history,
                            temperature=0.6,
                            max_tokens=2048
                        )
                        
                        response_text = completion.choices[0].message.content
                        
                        status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)
                        with chat_container:
                            with st.chat_message("assistant"):
                                st.markdown(f"<div style='font-size:1.15rem; color:#ffffff;'>{response_text}</div>", unsafe_allow_html=True)
                        st.session_state.messages.append({"role": "assistant", "content": response_text})
                    
                    except Exception as e:
                        status.update(label="âŒ ì˜¤ë¥˜ ë°œìƒ", state="error", expanded=True)
                        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {str(e)}")
            
            st.rerun()