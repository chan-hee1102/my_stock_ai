import streamlit as st
import pandas as pd
import os
import google.generativeai as genai

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI STOCK COMMANDER", layout="wide")

# 2. Gemini AI ì„¤ì • (ë¸”ë¡œê·¸ ë° Google ê°€ì´ë“œ ë°˜ì˜)
if "GEMINI_API_KEY" in st.secrets:
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        # 404 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ì •í™•í•œ ëª¨ë¸ëª… ì§€ì •
        model = genai.GenerativeModel('models/gemini-1.5-flash')
    except Exception as e:
        st.error(f"AI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        model = None
else:
    st.error("Secretsì— API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    model = None

# 3. ê°•ë ¥í•œ ë””ìì¸ CSS (ê²€ì€ìƒ‰ í…Œë§ˆ ë° ë…¸ë€ ë°•ìŠ¤ ì˜ì—­ ë°°ê²½ìƒ‰ ìˆ˜ì •)
st.markdown("""
    <style>
    /* ì „ì²´ ë°°ê²½ìƒ‰ */
    .stApp { background-color: #05070a; }
    
    /* ì„¹ì…˜ í—¤ë” */
    .section-header { color: #ffffff; font-size: 1.1rem; font-weight: 700; margin-bottom: 15px; border-left: 4px solid #00e5ff; padding-left: 10px; }
    
    /* ì¤‘ì•™ ìƒì„¸ ë¶„ì„ ë°•ìŠ¤ */
    .terminal-box { background-color: #1c2128; border: 1px solid #30363d; border-radius: 12px; padding: 25px; height: 700px; overflow-y: auto; color: white; }
    
    /* ì™¼ìª½ ì¢…ëª© ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton > button { 
        width: 100%; background-color: #1c2128; color: #ffffff; 
        border: 1px solid #30363d; margin-bottom: 8px; text-align: left; padding: 12px;
    }
    
    /* [ìš”ì²­] ì˜¤ë¥¸ìª½ ì±„íŒ… ì „ì²´ ì˜ì—­(ë…¸ë€ ë°•ìŠ¤ ë¶€ë¶„) ë°°ê²½ìƒ‰ ê°•ì œ ì§€ì • */
    [data-testid="stChatMessageContainerArea"] {
        background-color: #1c2128 !important;
        border: 1px solid #30363d !important;
        border-radius: 12px !important;
        padding: 10px !important;
    }

    /* ì±„íŒ… ë§í’ì„  ìƒ‰ìƒ êµ¬ë¶„ */
    [data-testid="stChatMessage"] { background-color: #2d333b !important; border-radius: 10px; }
    </style>
    """, unsafe_allow_html=True)

# 4. ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_data():
    out_dir = "outputs"
    if not os.path.exists(out_dir): return None
    files = [f for f in os.listdir(out_dir) if f.startswith("final_result_") and f.endswith(".csv")]
    if not files: return None
    latest_file = sorted(files)[-1]
    df = pd.read_csv(os.path.join(out_dir, latest_file))
    df['ì¢…ëª©ì½”ë“œ'] = df['ì¢…ëª©ì½”ë“œ'].astype(str).str.zfill(6)
    return df

data = load_data()

# 5. ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ (ë‹µë³€ ì‚¬ë¼ì§ ë°©ì§€ í•µì‹¬)
if "messages" not in st.session_state:
    st.session_state.messages = []
if data is not None and "selected_stock" not in st.session_state:
    st.session_state.selected_stock = data.iloc[0].to_dict()

# 6. í™”ë©´ êµ¬ì„±
if data is not None:
    col1, col2, col3 = st.columns([2.2, 4.5, 3.3])

    with col1: # ì™¼ìª½: ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (ë²ˆí˜¸ ì¶”ê°€)
        st.markdown('<div class="section-header">ğŸ“‚ í¬ì°© ì¢…ëª©</div>', unsafe_allow_html=True)
        with st.container(height=700):
            for i, (idx, row) in enumerate(data.iterrows()):
                if st.button(f"{i+1}. {row['ì¢…ëª©ëª…']} | {row['ê±°ë˜ëŒ€ê¸ˆ(ì–µ)']}ì–µ", key=f"s_{i}"):
                    st.session_state.selected_stock = row.to_dict()
                    st.rerun()

    with col2: # ì¤‘ì•™: ìƒì„¸ ë¶„ì„ ì°½
        stock = st.session_state.selected_stock
        st.markdown(f'<div class="section-header">ğŸ“Š {stock["ì¢…ëª©ëª…"]} ë¶„ì„</div>', unsafe_allow_html=True)
        st.markdown(f"""
            <div class="terminal-box">
                <h1 style="color:#00e5ff; margin-top:0;">{stock['ì¢…ëª©ëª…']}</h1>
                <p style="color:#8b949e;">ì½”ë“œ: {stock['ì¢…ëª©ì½”ë“œ']} | ê±°ë˜ëŒ€ê¸ˆ: {stock['ê±°ë˜ëŒ€ê¸ˆ(ì–µ)']}ì–µ</p>
                <hr style="border-color:#333;">
                <p>ì°¨íŠ¸ íë¦„ê³¼ ìˆ˜ê¸‰ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì€ ìš°ì¸¡ AIì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”.</p>
            </div>
        """, unsafe_allow_html=True)

    with col3: # ì˜¤ë¥¸ìª½: AI ì±„íŒ… (ë””ìì¸ ë° ë‹µë³€ ìœ ì§€ ì ìš©)
        st.markdown('<div class="section-header">ğŸ’¬ AI Commander</div>', unsafe_allow_html=True)
        
        # ì±„íŒ… ë©”ì‹œì§€ê°€ í‘œì‹œë  ì»¨í…Œì´ë„ˆ
        chat_container = st.container(height=600)
        
        # [ì¤‘ìš”] ì €ì¥ëœ ëŒ€í™” ë‚´ìš©ì„ ë¨¼ì € í™”ë©´ì— ê·¸ë¦¼ (ì‚¬ë¼ì§ ë°©ì§€)
        with chat_container:
            for m in st.session_state.messages:
                with st.chat_message(m["role"]):
                    st.markdown(m["content"])

        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with chat_container:
                with st.chat_message("user"):
                    st.markdown(prompt)
            
            if model:
                try:
                    with chat_container:
                        with st.chat_message("assistant"):
                            with st.spinner("ë¶„ì„ ì¤‘..."):
                                cur = st.session_state.selected_stock
                                full_query = f"ì¢…ëª©: {cur['ì¢…ëª©ëª…']}, ì§ˆë¬¸: {prompt}"
                                response = model.generate_content(full_query)
                                answer = response.text
                                st.markdown(answer)
                                # ë‹µë³€ì„ ì„¸ì…˜ì— ì¦‰ì‹œ ì €ì¥
                                st.session_state.messages.append({"role": "assistant", "content": answer})
                except Exception as e:
                    st.error(f"AI ì˜¤ë¥˜: {e}")
            
            # ìƒíƒœ í™•ì • ë° í™”ë©´ ê°±ì‹ ì„ ìœ„í•´ ë¦¬ëŸ°
            st.rerun()
else:
    st.error("ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")