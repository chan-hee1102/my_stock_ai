import streamlit as st
import pandas as pd
import os
import google.generativeai as genai

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI STOCK COMMANDER", layout="wide")

# 2. Gemini AI ì„¤ì • (ê°€ì¥ ì•ˆì „í•œ ì´ˆê¸°í™” ë°©ì‹)
if "GEMINI_API_KEY" in st.secrets:
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        # ëª¨ë¸ ê°ì²´ë¥¼ ìƒì„±í•  ë•Œ ì—ëŸ¬ê°€ ë‚˜ì§€ ì•Šë„ë¡ ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”
        model = genai.GenerativeModel('gemini-1.5-flash')
    except Exception as e:
        model = None
else:
    model = None

# 3. ë””ìì¸ CSS (ì±„íŒ…ì°½ ë°°ê²½ì„ ê°•ì œë¡œ ê½‰ ì±„ìš°ëŠ” ì„¤ì •)
st.markdown("""
    <style>
    .stApp { background-color: #05070a; }
    .section-header { color: #ffffff; font-size: 1.1rem; font-weight: 700; margin-bottom: 15px; border-left: 4px solid #00e5ff; padding-left: 10px; }
    
    /* ì¤‘ì•™ ìƒì„¸ ë¶„ì„ ë°•ìŠ¤ */
    .terminal-box { background-color: #1c2128; border: 1px solid #30363d; border-radius: 12px; padding: 25px; height: 700px; }
    
    /* ì™¼ìª½ ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton > button { 
        width: 100%; background-color: #1c2128; color: #ffffff; 
        border: 1px solid #30363d; margin-bottom: 8px; text-align: left; padding: 12px;
    }
    
    /* [í•µì‹¬] ë…¸ë€ ë°•ìŠ¤ ì˜ì—­ì„ í†µì§¸ë¡œ íšŒìƒ‰ ìƒìë¡œ ë§Œë“œëŠ” ì„¤ì • */
    /* Streamlit ì»¨í…Œì´ë„ˆ ìì²´ì— ë°°ê²½ìƒ‰ê³¼ ë†’ì´ë¥¼ ê°•ì œë¡œ ë¶€ì—¬í•©ë‹ˆë‹¤. */
    div[data-testid="stVerticalBlockBorderWrapper"]:has(div[data-testid="stChatMessage"]) {
        background-color: #1c2128 !important;
        border: 1px solid #30363d !important;
        border-radius: 12px !important;
        padding: 20px !important;
        min-height: 600px !important;
    }
    
    /* ì±„íŒ… ë§í’ì„  (êµ¬ë¶„ì„ ìœ„í•´ ë” ë°ê²Œ) */
    [data-testid="stChatMessage"] { 
        background-color: #2d333b !important; 
        border: 1px solid #444c56 !important;
    }
    </style>
    """, unsafe_allow_html=True)

# 4. ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_data():
    out_dir = "outputs"
    if not os.path.exists(out_dir): return None
    files = [f for f in os.listdir(out_dir) if f.startswith("final_result_") and f.endswith(".csv")]
    if not files: return None
    latest_file = sorted(files)[-1]
    df = pd.read_csv(os.path.join(out_dir, latest_file))
    df['ì¢…ëª©ì½”ë“œ'] = df['ì¢…ëª©ì½”ë“œ'].astype(str).str.zfill(6)
    return df

data = load_data()

if data is not None:
    if "selected_stock" not in st.session_state:
        st.session_state.selected_stock = data.iloc[0].to_dict()
    if "messages" not in st.session_state:
        st.session_state.messages = []

    col1, col2, col3 = st.columns([2.2, 4.5, 3.3])

    with col1: # ì™¼ìª½: ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (ë²ˆí˜¸ ì¶”ê°€ ì™„ë£Œ)
        st.markdown('<div class="section-header">ğŸ“‚ í¬ì°©ëœ ì¢…ëª©</div>', unsafe_allow_html=True)
        with st.container(height=700):
            # enumerateë¥¼ ì¨ì„œ 1ë¶€í„° ë²ˆí˜¸ë¥¼ ë§¤ê¹ë‹ˆë‹¤.
            for i, (idx, row) in enumerate(data.iterrows()):
                label = f"{i+1}. {row['ì¢…ëª©ëª…']} | {row['ê±°ë˜ëŒ€ê¸ˆ(ì–µ)']}ì–µ"
                if st.button(label, key=f"stock_{i}"):
                    st.session_state.selected_stock = row.to_dict()
                    st.rerun()

    with col2: # ì¤‘ì•™: ìƒì„¸ ë¶„ì„
        stock = st.session_state.selected_stock
        st.markdown(f'<div class="section-header">ğŸ“Š {stock["ì¢…ëª©ëª…"]} ë¶„ì„</div>', unsafe_allow_html=True)
        st.markdown(f"""
            <div class="terminal-box">
                <h1 style="color:#00e5ff; margin-top:0;">{stock['ì¢…ëª©ëª…']}</h1>
                <p style="color:#8b949e;">ì½”ë“œ: {stock['ì¢…ëª©ì½”ë“œ']} | ê±°ë˜ëŒ€ê¸ˆ: {stock['ê±°ë˜ëŒ€ê¸ˆ(ì–µ)']}ì–µ</p>
                <hr style="border-color:#333;">
                <p style="color:#ced4da;">í˜„ì¬ ì°¨íŠ¸ ìœ„ì¹˜ì™€ ìˆ˜ê¸‰ ìƒí™©ì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.<br>êµ¬ì²´ì ì¸ ëŒ€ì‘ ì „ëµì€ AIì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”.</p>
            </div>
        """, unsafe_allow_html=True)

    with col3: # ì˜¤ë¥¸ìª½: AI ì±„íŒ… (ë°°ê²½ìƒ‰ ê½‰ ì±„ìš°ê¸°)
        st.markdown('<div class="section-header">ğŸ’¬ AI Commander</div>', unsafe_allow_html=True)
        
        # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ ì˜ì—­
        chat_placeholder = st.container(height=550)
        with chat_placeholder:
            for m in st.session_state.messages:
                with st.chat_message(m["role"]):
                    st.markdown(m["content"])

        # ì§ˆë¬¸ ì…ë ¥ ë° AI ë¡œì§
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            if model:
                try:
                    # AI ì‘ë‹µ ìƒì„±
                    cur = st.session_state.selected_stock
                    context = f"ë‹¹ì‹ ì€ ì£¼ì‹ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {cur['ì¢…ëª©ëª…']}(ì½”ë“œ:{cur['ì¢…ëª©ì½”ë“œ']}) ì¢…ëª©ì— ëŒ€í•´ ë¶„ì„í•´ì£¼ì„¸ìš”."
                    response = model.generate_content(f"{context}\n\nì§ˆë¬¸: {prompt}")
                    st.session_state.messages.append({"role": "assistant", "content": response.text})
                except Exception as e:
                    st.session_state.messages.append({"role": "assistant", "content": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"})
            
            st.rerun()
else:
    st.error("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")