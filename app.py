import streamlit as st
import pandas as pd
import os
import google.generativeai as genai

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI STOCK COMMANDER", layout="wide")

# 2. [ë¸”ë¡œê·¸ í•™ìŠµ ë°˜ì˜] Gemini AI ì„¤ì •
if "GEMINI_API_KEY" in st.secrets:
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        # ëª¨ë¸ëª…ì„ ëª…í™•íˆ ì§€ì •í•˜ì—¬ 404 ë°©ì§€
        model = genai.GenerativeModel('models/gemini-1.5-flash')
    except Exception as e:
        model = None
else:
    model = None

# 3. ë””ìì¸ CSS ë³µêµ¬ (ë‹¤ì‹œ ê²€ì€ìƒ‰ í…Œë§ˆë¡œ)
st.markdown("""
    <style>
    .stApp { background-color: #05070a; }
    .section-header { color: #ffffff; font-size: 1.1rem; font-weight: 700; margin-bottom: 15px; border-left: 4px solid #00e5ff; padding-left: 10px; }
    .content-box { background-color: #1c2128; border: 1px solid #30363d; border-radius: 12px; padding: 20px; height: 600px; overflow-y: auto; color: white; }
    .stButton > button { width: 100%; background-color: #1c2128; color: #ffffff; border: 1px solid #30363d; margin-bottom: 8px; text-align: left; }
    /* ì±„íŒ… ì˜ì—­ ë°°ê²½ìƒ‰ ê³ ì • */
    [data-testid="stChatMessageContainer"] { background-color: #1c2128 !important; border-radius: 10px; }
    </style>
    """, unsafe_allow_html=True)

# 4. ë°ì´í„° ë¡œë“œ
def load_data():
    out_dir = "outputs"
    if not os.path.exists(out_dir): return None
    files = [f for f in os.listdir(out_dir) if f.startswith("final_result_") and f.endswith(".csv")]
    if not files: return None
    latest_file = sorted(files)[-1]
    df = pd.read_csv(os.path.join(out_dir, latest_file))
    df['ì¢…ëª©ì½”ë“œ'] = df['ì¢…ëª©ì½”ë“œ'].astype(str).str.zfill(6)
    return df

data = load_data()

# 5. ì„¸ì…˜ ìƒíƒœ (ë‹µë³€ ì €ì¥ ë° ìœ ì§€)
if "messages" not in st.session_state:
    st.session_state.messages = []
if data is not None and "selected_stock" not in st.session_state:
    st.session_state.selected_stock = data.iloc[0].to_dict()

# 6. í™”ë©´ êµ¬ì„±
if data is not None:
    col1, col2, col3 = st.columns([2, 4, 3])

    with col1: # ì™¼ìª½: ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (ë²ˆí˜¸ ì¶”ê°€)
        st.markdown('<div class="section-header">ğŸ“‚ í¬ì°© ì¢…ëª©</div>', unsafe_allow_html=True)
        with st.container(height=650):
            for i, (idx, row) in enumerate(data.iterrows()):
                if st.button(f"{i+1}. {row['ì¢…ëª©ëª…']} | {row['ê±°ë˜ëŒ€ê¸ˆ(ì–µ)']}ì–µ", key=f"s_{i}"):
                    st.session_state.selected_stock = row.to_dict()
                    st.rerun()

    with col2: # ì¤‘ì•™: ìƒì„¸ ë¶„ì„
        stock = st.session_state.selected_stock
        st.markdown(f'<div class="section-header">ğŸ“Š {stock["ì¢…ëª©ëª…"]} ë¶„ì„</div>', unsafe_allow_html=True)
        st.markdown(f"""<div class="content-box">
            <h1 style="color:#00e5ff;">{stock['ì¢…ëª©ëª…']}</h1>
            <p>ì½”ë“œ: {stock['ì¢…ëª©ì½”ë“œ']} | ê±°ë˜ëŒ€ê¸ˆ: {stock['ê±°ë˜ëŒ€ê¸ˆ(ì–µ)']}ì–µ</p>
            <hr>
            <p>ì´ ì¢…ëª©ì˜ ìƒì„¸ ë¶„ì„ ë°ì´í„°ëŠ” AI Commanderì—ê²Œ ì§ˆë¬¸í•˜ì—¬ í™•ì¸í•˜ì„¸ìš”.</p>
        </div>""", unsafe_allow_html=True)

    with col3: # ì˜¤ë¥¸ìª½: AI ì±„íŒ… (ë‹µë³€ ê³ ì • ë¡œì§)
        st.markdown('<div class="section-header">ğŸ’¬ AI Commander</div>', unsafe_allow_html=True)
        chat_container = st.container(height=550)
        
        # ì €ì¥ëœ ë©”ì‹œì§€ ì¶œë ¥ (ì´ê²Œ ì—†ìœ¼ë©´ ë‹µì¥ì´ ì‚¬ë¼ì§)
        with chat_container:
            for m in st.session_state.messages:
                with st.chat_message(m["role"]):
                    st.markdown(m["content"])

        if prompt := st.chat_input("ì¢…ëª©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”"):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° í‘œì‹œ
            st.session_state.messages.append({"role": "user", "content": prompt})
            with chat_container:
                with st.chat_message("user"):
                    st.markdown(prompt)
            
            # AI ë‹µë³€ ìƒì„±
            if model:
                try:
                    with chat_container:
                        with st.chat_message("assistant"):
                            response = model.generate_content(f"{stock['ì¢…ëª©ëª…']} ë¶„ì„ ì§ˆë¬¸: {prompt}")
                            st.markdown(response.text)
                            # ë‹µë³€ì„ ì„¸ì…˜ì— ì¦‰ì‹œ ì €ì¥
                            st.session_state.messages.append({"role": "assistant", "content": response.text})
                except Exception as e:
                    st.error(f"AI ì˜¤ë¥˜: {e}")
            st.rerun() # ì „ì²´ ìƒíƒœ ë°˜ì˜ì„ ìœ„í•´ ë§ˆì§€ë§‰ì— ë¦¬ëŸ°
else:
    st.error("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")