# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import os
from groq import Groq
from datetime import datetime

# 1) í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI STOCK COMMANDER", layout="wide")

# 2) ë””ìì¸ CSS (ì°¬í¬ë‹˜ì˜ ì‹œê·¸ë‹ˆì²˜ ë¸”ë™ & ë¯¼íŠ¸ ë””ìì¸)
st.markdown("""
    <style>
    .stApp { background-color: #05070a; }
    [data-testid="stHorizontalBlock"] > div {
        background-color: #1c2128; border-radius: 15px; padding: 25px; border: 1px solid #30363d;
    }
    .section-header { 
        color: #00e5ff !important; font-size: 1.5rem !important; font-weight: 800; 
        margin-bottom: 25px; border-left: 6px solid #00e5ff; padding-left: 15px; 
    }
    div[data-testid="stColumn"]:nth-of-type(1) .stButton > button {
        width: 100% !important; background-color: transparent !important; color: #ffffff !important;
        border: none !important; font-size: 2.2rem !important; font-weight: 800 !important;
        text-align: left !important; padding: 12px 0px !important; transition: 0.3s;
    }
    div[data-testid="stColumn"]:nth-of-type(1) .stButton > button:hover { color: #00e5ff !important; transform: translateX(8px); }
    .report-box { background-color: #0d1117; border: 1px solid #30363d; border-radius: 12px; padding: 25px; margin-bottom: 20px; }
    .report-text { color: #e0e6ed !important; font-size: 1.2rem !important; line-height: 1.8; }
    .highlight-mint { color: #00e5ff !important; font-weight: 800; }
    div[data-testid="stChatInput"] { background-color: #ffffff !important; border-radius: 15px !important; padding: 10px !important; }
    div[data-testid="stChatInput"] textarea { color: #000000 !important; font-size: 1.15rem !important; }
    </style>
    """, unsafe_allow_html=True)

# 3) ë°ì´í„° ë¡œë“œ ë¡œì§
def load_data():
    out_dir = "outputs"
    if not os.path.exists(out_dir): return None, None
    files = [f for f in os.listdir(out_dir) if f.startswith("final_result_") and f.endswith(".csv")]
    if not files: return None, None
    latest_file = sorted(files)[-1]
    
    try:
        raw_date = latest_file.split('_')[-1].replace('.csv', '')
        date_str = f"{raw_date[:4]}-{raw_date[4:6]}-{raw_date[6:]}"
    except:
        date_str = datetime.now().strftime('%Y-%m-%d')
        
    df = pd.read_csv(os.path.join(out_dir, latest_file))
    if "ì¢…ëª©ì½”ë“œ" in df.columns: 
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).str.zfill(6)
    return df, date_str

data, data_date = load_data()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state: 
    st.session_state.messages = []
if data is not None and "selected_stock" not in st.session_state:
    st.session_state.selected_stock = data.iloc[0].to_dict()

# Groq í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
def get_groq_client():
    key = st.secrets.get("GROQ_API_KEY")
    if not key: return None
    return Groq(api_key=key)

client = get_groq_client()

# 4) ë©”ì¸ ë ˆì´ì•„ì›ƒ êµ¬ì„±
if data is not None:
    col_list, col_chat = st.columns([2, 8])

    with col_list:
        st.markdown(f'<div class="section-header">ğŸ“‚ {data_date} í¬ì°© ì¢…ëª©</div>', unsafe_allow_html=True)
        with st.container(height=850):
            for i, (idx, row) in enumerate(data.iterrows()):
                is_selected = st.session_state.selected_stock['ì¢…ëª©ëª…'] == row['ì¢…ëª©ëª…']
                display_name = f"â–¶ {row['ì¢…ëª©ëª…']} â—€" if is_selected else f"  {row['ì¢…ëª©ëª…']}"
                if st.button(display_name, key=f"stock_btn_{i}"):
                    st.session_state.selected_stock = row.to_dict()
                    st.session_state.messages = []
                    st.rerun()
                st.markdown("<hr style='margin:5px 0; border:0.5px solid #30363d; opacity:0.3;'>", unsafe_allow_html=True)

    with col_chat:
        stock = st.session_state.selected_stock
        st.markdown(f'<div class="section-header">ğŸ’¬ {stock["ì¢…ëª©ëª…"]} AI ì •ë°€ ë¦¬í¬íŠ¸</div>', unsafe_allow_html=True)
        
        st.markdown(f"""
        <div class="report-box"><div class="report-text">
            <span class="highlight-mint">â— ë¶„ì„ ëŒ€ìƒ:</span> {stock["ì¢…ëª©ëª…"]} ({stock.get('ì¢…ëª©ì½”ë“œ', '000000')})<br>
            <span class="highlight-mint">â— AI ì—”ì§„:</span> Llama-3.3-70B (Versatile Mode)<br>
            <span class="highlight-mint">â— ì„¤ì •:</span> í•œêµ­ì–´ ë² ì´ìŠ¤ + ì£¼ì‹ ì „ë¬¸ ì˜ì–´ ë‹¨ì–´ í˜¼ìš© ëª¨ë“œ
        </div></div>
        """, unsafe_allow_html=True)

        chat_container = st.container(height=650)
        with chat_container:
            for m in st.session_state.messages:
                with st.chat_message(m["role"]):
                    st.markdown(f"<div style='font-size:1.15rem; color:#ffffff;'>{m['content']}</div>", unsafe_allow_html=True)

        if prompt := st.chat_input(f"{stock['ì¢…ëª©ëª…']}ì˜ ì „ë§ì„ ë¬¼ì–´ë³´ì„¸ìš”!"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with chat_container:
                with st.chat_message("user"):
                    st.markdown(f"<div style='font-size:1.15rem; color:#ffffff;'>{prompt}</div>", unsafe_allow_html=True)
            
            if client:
                with st.status("AI ì „ëµê°€ê°€ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤...", expanded=True) as status:
                    try:
                        # --- ì§€ì¹¨ ìˆ˜ì •: ì˜ì–´ ë‹¨ì–´ í—ˆìš©í•˜ë˜ ì¼ë³¸ì–´ëŠ” ê¸ˆì§€ ---
                        history = [{
                            "role": "system", 
                            "content": (
                                f"ë‹¹ì‹ ì€ {stock['ì¢…ëª©ëª…']} ì „ë¬¸ ì£¼ì‹ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ë‚ ì§œëŠ” {datetime.now().strftime('%Y-%m-%d')}ì…ë‹ˆë‹¤.\n"
                                f"ì§€ì¹¨:\n"
                                f"1. ì£¼ì‹ ì „ë¬¸ ìš©ì–´, ê¸°ì—…ëª…, ê¸°ìˆ  ìš©ì–´ëŠ” **ì˜ë¬¸(English)**ìœ¼ë¡œ ì ì ˆíˆ ì„ì–´ì„œ ë‹µë³€í•˜ì„¸ìš”.\n"
                                f"2. ë‹¨, ë¬¸ì¥ì˜ êµ¬ì„±ê³¼ ë² ì´ìŠ¤ëŠ” ë°˜ë“œì‹œ **í•œêµ­ì–´**ì—¬ì•¼ í•©ë‹ˆë‹¤.\n"
                                f"3. ì ˆëŒ€ë¡œ ì¼ë³¸ì–´ í•œìë‚˜ ì¼ë³¸ì–´ ì ‘ì†ì‚¬(ì˜ˆ: ãŸã ã—, è—è‰² ë“±)ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n"
                                f"4. ê°€ë…ì„±ì„ ìœ„í•´ ë¶ˆë › í¬ì¸íŠ¸ë‚˜ ìˆ˜ì¹˜ ë°ì´í„°ë¥¼ ì ê·¹ í™œìš©í•˜ì„¸ìš”."
                            )
                        }]
                        for m in st.session_state.messages[-10:]:
                            history.append({"role": m["role"], "content": m["content"]})
                        
                        # 2026ë…„ ê¸°ì¤€ ìµœì  ëª¨ë¸
                        completion = client.chat.completions.create(
                            model="llama-3.3-70b-versatile",
                            messages=history,
                            temperature=0.7, 
                            max_tokens=2048
                        )
                        
                        response_text = completion.choices[0].message.content
                        
                        status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)
                        with chat_container:
                            with st.chat_message("assistant"):
                                st.markdown(f"<div style='font-size:1.15rem; color:#ffffff;'>{response_text}</div>", unsafe_allow_html=True)
                        st.session_state.messages.append({"role": "assistant", "content": response_text})
                    
                    except Exception as e:
                        status.update(label="âŒ ë¶„ì„ ì§€ì—°", state="error", expanded=True)
                        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            st.rerun()